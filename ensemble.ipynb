{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c780d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "from network_module import Net\n",
    "from hydra.utils import instantiate\n",
    "from datamodule import PolypGenDataset\n",
    "import torch\n",
    "from lightning.pytorch import loggers\n",
    "import numpy as np\n",
    "from monai import metrics as mm\n",
    "from visualize_results import save_visualization_grid\n",
    "\n",
    "os.environ['NO_ALBUMENTATIONS_UPDATE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f4ac89d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading multiple models for ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading multiple models for ensemble...\")\n",
    "\n",
    "# Define your model configurations and checkpoint paths\n",
    "model_configs = [\n",
    "    {\"config_name\": \"config\",                \"checkpoint\": \"../logs_drive/efficientnet-b4_32/version_2/model_checkpoint.ckpt\"},\n",
    "    {\"config_name\": \"config_attention_unet\", \"checkpoint\": \"../logs_drive/attention_unet/version_1/model_checkpoint.ckpt\"},\n",
    "    {\"config_name\": \"config_segresnet\",      \"checkpoint\": \"../logs_drive/segresnet/version_1/model_checkpoint.ckpt\"},\n",
    "]\n",
    "\n",
    "models = []\n",
    "# Load each model with its respective config\n",
    "for model_config in model_configs:\n",
    "    with initialize(config_path=\"config\", version_base=None):\n",
    "        cfg = compose(config_name=model_config[\"config_name\"])\n",
    "        checkpoint_path = model_config[\"checkpoint\"]\n",
    "        model = instantiate(cfg.model.object)\n",
    "        net = Net.load_from_checkpoint(\n",
    "            checkpoint_path,\n",
    "            model=model,\n",
    "            criterion=instantiate(cfg.criterion),\n",
    "            optimizer=cfg.optimizer,\n",
    "            lr=cfg.lr,\n",
    "            scheduler=cfg.scheduler,\n",
    "        )\n",
    "        # net = net.load_from_checkpoint(checkpoint_path)\n",
    "        net.eval()  # Set to evaluation mode\n",
    "        models.append(net)\n",
    "\n",
    "# Load dataset (using the last config for simplicity)\n",
    "dataset = PolypGenDataset(batch_size=cfg.batch_size, img_size=cfg.img_size)\n",
    "trainer = instantiate(cfg.trainer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b63c05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from model 1/3\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:16<00:00,  0.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from model 2/3\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [02:40<00:00,  0.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from model 3/3\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.11it/s]\n",
      "inside for: torch.Size([88, 1, 512, 512]), type: <class 'torch.Tensor'>\n",
      "inside for: torch.Size([88, 1, 512, 512]), type: <class 'torch.Tensor'>\n",
      "inside for: torch.Size([88, 1, 512, 512]), type: <class 'torch.Tensor'>\n",
      "After stacking all models: torch.Size([3, 88, 1, 512, 512]), type: <class 'torch.Tensor'>\n",
      "After averaging: torch.Size([88, 1, 512, 512]), type: <class 'torch.Tensor'>\n",
      "After final thresholding: torch.Size([88, 1, 512, 512]), type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from all models\n",
    "all_models_prediction_outputs = []\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Getting predictions from model {i+1}/{len(models)}\")\n",
    "    prediction_outputs = trainer.predict(model, dataset)\n",
    "    all_models_prediction_outputs.append(prediction_outputs)\n",
    "\n",
    "# Implement voting system\n",
    "# ensemble_predictions = ensemble_voting(all_models_predictions)\n",
    "voting_batch_probs = []\n",
    "for single_model_prediction_outputs in all_models_prediction_outputs:\n",
    "    \n",
    "    batch_probs = [batch['probabilities'] for batch in single_model_prediction_outputs]\n",
    "    voting_batch_probs.append(torch.cat(batch_probs))\n",
    "    print(f\"inside for: {voting_batch_probs[-1].shape}, type: {type(voting_batch_probs[-1])}\")\n",
    "voting_probs = torch.stack(voting_batch_probs)\n",
    "print(f\"After stacking all models: {voting_probs.shape}, type: {type(voting_probs)}\")\n",
    "\n",
    "# Soft voting: average probabilities, then threshold\n",
    "ensemble_probs = voting_probs.mean(dim=0)\n",
    "print(f\"After averaging: {ensemble_probs.shape}, type: {type(ensemble_probs)}\")\n",
    "\n",
    "# You can still threshold at the end if you need binary output\n",
    "ensemble_predictions = (ensemble_probs > 0.5).float()\n",
    "print(f\"After final thresholding: {ensemble_predictions.shape}, type: {type(ensemble_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c331232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_prediction_outputs = all_models_prediction_outputs[0]\n",
    "\n",
    "batch_targets = [batch['masks'] for batch in single_model_prediction_outputs]\n",
    "\n",
    "# targets_list.append(torch.cat(batch_targets))\n",
    "\n",
    "targets = torch.cat(batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0030fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "get_dice = mm.DiceMetric(include_background=False, reduction=\"mean\")\n",
    "get_iou = mm.MeanIoU(include_background=False, reduction=\"mean\")\n",
    "get_accuracy = mm.ConfusionMatrixMetric(include_background=False, metric_name=\"accuracy\")\n",
    "get_recall = mm.ConfusionMatrixMetric(include_background=False, metric_name=\"sensitivity\")\n",
    "get_precision = mm.ConfusionMatrixMetric(include_background=False, metric_name=\"precision\")\n",
    "\n",
    "# Ensure predictions are long type for metrics\n",
    "predictions = ensemble_predictions.long()\n",
    "targets = targets.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7028d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "get_dice(predictions, targets)\n",
    "get_iou(predictions, targets)\n",
    "get_accuracy(predictions, targets)\n",
    "get_recall(predictions, targets)\n",
    "get_precision(predictions, targets)\n",
    "\n",
    "# Get results\n",
    "dice = get_dice.aggregate()[0].item()\n",
    "iou = get_iou.aggregate()[0].item()\n",
    "accuracy = get_accuracy.aggregate()[0].item()\n",
    "recall = get_recall.aggregate()[0].item()\n",
    "precision = get_precision.aggregate()[0].item()\n",
    "f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "f2 = 5 * (precision * recall) / (4 * precision + recall + 1e-8)\n",
    "\n",
    "ensemble_metrics = {\n",
    "    'test_dice': dice,\n",
    "    'test_iou': iou,\n",
    "    'test_accuracy': accuracy,\n",
    "    'test_recall': recall,\n",
    "    'test_precision': precision,\n",
    "    'test_f1': f1,\n",
    "    'test_f2': f2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "219de8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_dice': 0.7933390140533447,\n",
       " 'test_iou': 0.7223753333091736,\n",
       " 'test_accuracy': 0.9763011336326599,\n",
       " 'test_recall': 0.8135696649551392,\n",
       " 'test_precision': 0.8791412711143494,\n",
       " 'test_f1': 0.8450854188064955,\n",
       " 'test_f2': 0.8258896190632325}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eebb545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics logged to TensorBoard!\n",
      "View logs at: ../logs_drive/ensemble\\version_4\n"
     ]
    }
   ],
   "source": [
    "logger = loggers.TensorBoardLogger(\"../logs_drive/\", name='ensemble')\n",
    "\n",
    "# Log metrics to TensorBoard\n",
    "\n",
    "# for metric_name, metric_value in ensemble_metrics.items():\n",
    "#     logger.experiment.add_scalar(f'ensemble/{metric_name}', metric_value, 0)\n",
    "\n",
    "# Log hyperparameters and metrics together\n",
    "logger.log_hyperparams(\n",
    "    params={\n",
    "        'ensemble_method': 'average',  # or 'majority'\n",
    "        'num_models': len(models),\n",
    "        'model_configs': [config['config_name'] for config in model_configs]\n",
    "    },\n",
    "    metrics=ensemble_metrics\n",
    ")\n",
    "\n",
    "print(\"Metrics logged to TensorBoard!\")\n",
    "print(f\"View logs at: {logger.log_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "26356395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 14760), started 2:25:04 ago. (Use '!kill 14760' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1995d6b70828650\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1995d6b70828650\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ../logs_drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4b58e892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 1, 512, 512])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c6c87191",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = all_models_prediction_outputs[0]\n",
    "ensemble_batches = torch.split(ensemble_predictions, cfg.batch_size, dim=0)\n",
    "\n",
    "for i, batch in enumerate(test_input):\n",
    "    batch.pop('probabilities', None)\n",
    "    batch['predictions'] = ensemble_batches[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "344c7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_visualization_grid(prediction_outputs, logger.log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effisegnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
